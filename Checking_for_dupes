
import os
import hashlib
import sys

#reads bytes
def chunk_reader(fobj, chunk_size = 1024):
    while True:
        chunk = fobj.read(chunk_size)
    if not chunk:
        return
    yield chunk
    #should check bytes, in a specified path
def check_for_duplicates(paths, hash=hashlib.sha1):
    hashes = {}
    for path in paths:
        for dirpath, dirnames, filenames in os.walk(path):

            for filename in filenames:
                full_path = os.path.join(dirpath, filename)
                hashobj = hash()
                for chunk in chunk_reader(open(full_path, 'rb')):
                    hashobj.update(chunk)
                file_id  = (hashobj.digest(), os.path.getsize(full_path))
                duplicate = hashes.get(file_id, None)
                if duplicate:
                    print ("Duplicate found %s and %s") % (full_path,duplicate)
                else:
                    hashes[file_id] = full_path

if sys.argv[1:]:
               check_for_duplicates(sys.argv[1:])
else:
                print ("Pass the paths as parameters so the script will run")

check_for_duplicates(r"C:\Users\Jacob\Desktop\music")
